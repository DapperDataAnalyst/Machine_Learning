{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1 Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Order does matter for a perceptron.\n",
    "\n",
    "Say we have three points in 2D space as follows:\n",
    "* Point 1: coordinates (1,1), label +1\n",
    "* Point 2: coordinates (-1,-1), label -1\n",
    "* Point 3: coordinates (1,-1), label -1\n",
    "\n",
    "We will now examine two different presentation orders to see how they may differ.\n",
    "\n",
    "First Order 1:\n",
    "1. Present Point 1, it is correctly classified\n",
    "2. Present Point 2, it is correctly classified\n",
    "3. Present Point 3, it is incorrectly classified\n",
    "\n",
    "In Order 1, the algorithm committed one mistake, and converges to a set of weights that correctly classifies all three points.\n",
    "\n",
    "Next, we examine Order 2:\n",
    "1. Present Point 2, it is correctly classified\n",
    "2. Present Point 1, it is incorrectly classied\n",
    "3. Present Point 3, it is incorrectly classified\n",
    "\n",
    "Under Order 2, the algorithm committed two mistakes, converging to a different set of weights than under Order 2, though still correctly classifying all points upon convergence.\n",
    "\n",
    "Thus we have shown that order of presentation can affect the mistake count and the final weight vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss function $\\phi (z) = max(0,-z)$ is known as a hinge loss function."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
