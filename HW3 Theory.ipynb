{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3 Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than compute the eigendecomposition of the $m \\times m$ matrix $X=AA^T$, we can define a $d \\times d$ matrix $Y=A^TA$.\n",
    "\n",
    "We can use the eigendecomposition of matrix Y to find the eigendecomposition of matrix X. We use our black box eigendecomposition algorithm on Y to find its eigenvectors and eigenvalues. Let us call the set of Y's eigenvalues {$\\lambda_1, \\lambda_2, \\ldots, \\lambda_d$} and the set of Y's eigenvectors {$v_1, v_2, \\ldots, v_d$}.\n",
    "\n",
    "We now exploit the relationship between X and A to find the eigenvectors and eigenvalues of X using the eigenvectors and eigenvalues of Y.\n",
    "\n",
    "The $i^{th}$ eigenvector of X is in fact $Av_i$ where $v_i$ is the $i^{th}$ eigenvector of Y.\n",
    "\n",
    "The $i^{th}$ eigenvalue of X is in fact $\\lambda_i$, the $i^{th}$ eigenvalue of Y.\n",
    "\n",
    "**Thus we have found the eigendecomposition of the $m \\times m$ matrix X using only matrix A and the eigendecomposition of the $d \\times d$ matrix Y.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) True\n",
    "\n",
    "(b) True\n",
    "\n",
    "(c) False\n",
    "\n",
    "(d) One solution is to identify these collinear variables and discard one of them. Another solution is to use PCA as a preprocessing step, as we know that the principal components resulting from a PCA operation are uncorrelated. We could use these principal componenets as the inputs to our regression."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
