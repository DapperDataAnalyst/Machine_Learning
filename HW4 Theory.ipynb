{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4 Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $Pr(X=i)$ to be a valid probability mass function, it must be the case that $\\Sigma Pr(x) = 1$\n",
    "\n",
    "$$Pr(X=1) + Pr(X=2) + Pr(X=3) = 1$$\n",
    "$$\\theta_1 + 2\\theta_1 + \\theta_2 = 1$$\n",
    "$$3\\theta_1 + \\theta_2 = 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the given information we have that:\n",
    "$$Pr(D | \\theta) = (\\theta_1^{s_1} * (2\\theta_1)^{s_2} * \\theta_2^{s_3})$$\n",
    "\n",
    "Next we find the log probability as:\n",
    "$$log Pr(D | \\theta) = log(\\theta_1^{s_1} * (2\\theta_1)^{s_2} * \\theta_2^{s_3})$$\n",
    "$$= log\\theta_1^{s_1} + log(2\\theta_2)^{s_2} + log\\theta_2^{s_3}$$\n",
    "$$= s_1log\\theta_1 + s_2(log2 + log\\theta_1) + s_3log\\theta_2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first find $\\hat{\\theta}$ by taking the derivative of the log likelihood with respect to $\\theta_1$. We also utilize the result found in Part (a) that $\\theta_2 = 1-3\\theta_1$:\n",
    "$$\\frac{d}{d\\theta_1}(log Pr(D | \\theta)) = \\frac{s_1}{\\theta_1} + \\frac{s_2}{\\theta_1} - \\frac{3s_3}{1-3\\theta_1} = 0$$\n",
    "$$\\frac{s_1+s_2}{\\theta_1} - \\frac{3s_3}{1-3\\theta_1} = 0$$\n",
    "$$\\frac{1-3\\theta_1}{\\theta_1} = \\frac{3s_3}{s_1 + s_2}$$\n",
    "$$\\frac{1}{\\theta_1} - 3 = \\frac{3s_3}{s_1 + s_2}$$\n",
    "$$\\frac{1}{\\theta_1} = \\frac{3s_3}{s_1 + s_2} + 3$$\n",
    "$$\\hat{\\theta_1} = \\frac{1}{\\frac{3s_3}{s_1 + s_2} + 3}$$\n",
    "$$\\hat{\\theta_1} = \\frac{s_1 + s_2}{3(s_1 + s_2 + s_3)}$$\n",
    "\n",
    "Substituting this $\\hat{\\theta_1}$, we can find $\\hat{\\theta_2}$ as:\n",
    "$$\\hat{\\theta_2} = 1-3\\hat{\\theta_1}$$\n",
    "$$\\hat{\\theta_2} = 1-3\\frac{s_1 + s_2}{3(s_1 + s_2 + s_3)}$$\n",
    "$$\\hat{\\theta_2} = \\frac{s_3}{s_1 + s_2 + s_3}$$\n",
    "\n",
    "Thus the maximum likelihood estimation for $\\hat{\\theta}$ is:\n",
    "$$\\hat{\\theta} = [\\frac{s_1 + s_2}{3(s_1 + s_2 + s_3)}, \\frac{s_3}{s_1 + s_2 + s_3}]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the information given in the question prompt we have:\n",
    "$$\\Pi_{i=1}^n Pr(x_1,\\dots,x_n | \\beta) = \\frac{1}{\\beta}e^{-\\frac{x_i}{\\beta}}$$\n",
    "\n",
    "Taking the log we have:\n",
    "$$log\\Pi_{i=1}^n Pr(x_1,\\dots,x_n | \\beta) = \\Sigma_{i=1}^n(log\\frac{1}{\\beta} - \\frac{x_i}{\\beta})$$\n",
    "$$= -nlog\\beta - \\frac{1}{\\beta}\\Sigma x_i$$\n",
    "\n",
    "Taking the derivative and setting equal to zero we have:\n",
    "$$\\frac{d}{d\\beta}log\\Pi_{i=1}^n Pr(x_1,\\dots,x_n | \\beta) = -\\frac{n}{\\beta} + \\frac{1}{\\beta^2}\\Sigma x_i = 0$$\n",
    "$$\\frac{1}{\\beta^2}\\Sigma x_i = \\frac{n}{\\beta}$$\n",
    "$$\\hat{\\beta} = \\frac{\\Sigma x_i}{n}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will find that the posterior is proportional to the likelihood times the prior:\n",
    "$$f(\\theta|data) \\propto f(data|\\theta) * f(\\theta)$$\n",
    "\n",
    "Note that the probability density function of a uniform distribution is typically represented as $\\frac{1}{b-a}$ and is thus a constant. Because of this, the probability desity function of the prior, $f(\\theta)$, can be absorbed into the proportion and omitted from our notation.\n",
    "\n",
    "The likelihood function takes the form of a binomial distribution as follows:\n",
    "$$f(data|\\theta) = {30\\choose5}\\theta^5 (1-\\theta)^{30-5}$$\n",
    "\n",
    "Finally we can write the posterior distribution as:\n",
    "$$f(\\theta|data) \\propto \\theta^5 (1-\\theta)^{30-5}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
